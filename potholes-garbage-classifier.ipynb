{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14232419,"sourceType":"datasetVersion","datasetId":9079827},{"sourceId":14235341,"sourceType":"datasetVersion","datasetId":9081886},{"sourceId":14271961,"sourceType":"datasetVersion","datasetId":9108061},{"sourceId":14346697,"sourceType":"datasetVersion","datasetId":9160474}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall -y protobuf tensorflow\n!pip install protobuf==3.20.3 tensorflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T08:29:42.835413Z","iopub.execute_input":"2025-12-27T08:29:42.835595Z","iopub.status.idle":"2025-12-27T08:30:44.361930Z","shell.execute_reply.started":"2025-12-27T08:29:42.835571Z","shell.execute_reply":"2025-12-27T08:30:44.361246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport shutil\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split\nimport json\n\nprint(\"✓ All libraries imported successfully!\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-07T15:26:46.059592Z","iopub.execute_input":"2026-02-07T15:26:46.059903Z","iopub.status.idle":"2026-02-07T15:27:02.913888Z","shell.execute_reply.started":"2026-02-07T15:26:46.059868Z","shell.execute_reply":"2026-02-07T15:27:02.913065Z"}},"outputs":[{"name":"stderr","text":"2026-02-07 15:26:48.011805: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1770478008.237511      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1770478008.303099      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1770478008.837234      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770478008.837277      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770478008.837280      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770478008.837283      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"✓ All libraries imported successfully!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Set random seeds for reproducibility\nnp.random.seed(42)\nkeras.utils.set_random_seed(42)\n\n# Configuration parameters\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 32\nEPOCHS = 20\nDATA_DIR = '/kaggle/input/final/Dataset'\n\nCLASSES_TO_USE = ['Garbage', 'Potholes']\n\nTRAIN_SPLIT = 0.7\nVAL_SPLIT = 0.15\nTEST_SPLIT = 0.15\n\nprint(f\"Configuration:\")\nprint(f\"  Image Size: {IMG_SIZE}\")\nprint(f\"  Batch Size: {BATCH_SIZE}\")\nprint(f\"  Epochs: {EPOCHS}\")\nprint(f\"  Data Directory: {DATA_DIR}\")\nprint(f\"  Classes to train: {CLASSES_TO_USE}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T15:28:07.988741Z","iopub.execute_input":"2026-02-07T15:28:07.989474Z","iopub.status.idle":"2026-02-07T15:28:07.995539Z","shell.execute_reply.started":"2026-02-07T15:28:07.989440Z","shell.execute_reply":"2026-02-07T15:28:07.994823Z"}},"outputs":[{"name":"stdout","text":"Configuration:\n  Image Size: (224, 224)\n  Batch Size: 32\n  Epochs: 20\n  Data Directory: /kaggle/input/final/Dataset\n  Classes to train: ['Garbage', 'Potholes']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    zoom_range=0.2,\n    shear_range=0.2,\n    fill_mode='nearest'\n)\n\n# Only rescaling for validation\nval_test_datagen = ImageDataGenerator(\n    rescale=1./255\n)\n\nprint(\"✓ Data generators created with augmentation settings\")\nprint(\"  Training: Augmentation enabled\")\nprint(\"  Validation & Test: Only rescaling\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T15:28:15.600967Z","iopub.execute_input":"2026-02-07T15:28:15.601490Z","iopub.status.idle":"2026-02-07T15:28:15.607322Z","shell.execute_reply.started":"2026-02-07T15:28:15.601455Z","shell.execute_reply":"2026-02-07T15:28:15.606561Z"}},"outputs":[{"name":"stdout","text":"✓ Data generators created with augmentation settings\n  Training: Augmentation enabled\n  Validation & Test: Only rescaling\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Create temporary directories for train/val/test split\nTEMP_DIR = '/kaggle/working/temp_data'\nTRAIN_DIR = os.path.join(TEMP_DIR, 'train')\nVAL_DIR = os.path.join(TEMP_DIR, 'val')\nTEST_DIR = os.path.join(TEMP_DIR, 'test')\n\n# Clean up if exists\nif os.path.exists(TEMP_DIR):\n    shutil.rmtree(TEMP_DIR)\n\n# Create directories\nfor class_name in CLASSES_TO_USE:\n    os.makedirs(os.path.join(TRAIN_DIR, class_name), exist_ok=True)\n    os.makedirs(os.path.join(VAL_DIR, class_name), exist_ok=True)\n    os.makedirs(os.path.join(TEST_DIR, class_name), exist_ok=True)\n\nprint(\"Splitting data into train/val/test sets...\")\n\n# Split data for each class\nfor class_name in CLASSES_TO_USE:\n    class_dir = os.path.join(DATA_DIR, class_name)\n    \n    # Get all image files\n    image_files = [f for f in os.listdir(class_dir) \n                   if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n    \n    # First split: separate test set\n    train_val_files, test_files = train_test_split(\n        image_files, \n        test_size=TEST_SPLIT, \n        random_state=42\n    )\n    \n    # Second split: separate train and validation\n    train_files, val_files = train_test_split(\n        train_val_files,\n        test_size=VAL_SPLIT/(TRAIN_SPLIT + VAL_SPLIT),  # Adjust ratio\n        random_state=42\n    )\n    \n    # Copy files to respective directories\n    for filename in train_files:\n        src = os.path.join(class_dir, filename)\n        dst = os.path.join(TRAIN_DIR, class_name, filename)\n        shutil.copy2(src, dst)\n    \n    for filename in val_files:\n        src = os.path.join(class_dir, filename)\n        dst = os.path.join(VAL_DIR, class_name, filename)\n        shutil.copy2(src, dst)\n    \n    for filename in test_files:\n        src = os.path.join(class_dir, filename)\n        dst = os.path.join(TEST_DIR, class_name, filename)\n        shutil.copy2(src, dst)\n    \n    print(f\"  {class_name}: {len(train_files)} train, {len(val_files)} val, {len(test_files)} test\")\n\nprint(\"\\n✓ Data split completed!\")\n\n# Load training data\ntrain_generator = train_datagen.flow_from_directory(\n    TRAIN_DIR,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',  # Changed to categorical for 3 classes\n    shuffle=True\n)\n\n# Load validation data\nval_generator = val_test_datagen.flow_from_directory(\n    VAL_DIR,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=False\n)\n\n# Load test data\ntest_generator = val_test_datagen.flow_from_directory(\n    TEST_DIR,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=False\n)\n\nprint(f\"\\n✓ Data generators created!\")\nprint(f\"  Training images: {train_generator.samples}\")\nprint(f\"  Validation images: {val_generator.samples}\")\nprint(f\"  Test images: {test_generator.samples}\")\nprint(f\"  Class indices: {train_generator.class_indices}\")\nprint(f\"  Number of classes: {train_generator.num_classes}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T15:28:37.035276Z","iopub.execute_input":"2026-02-07T15:28:37.035845Z","iopub.status.idle":"2026-02-07T15:31:01.367717Z","shell.execute_reply.started":"2026-02-07T15:28:37.035820Z","shell.execute_reply":"2026-02-07T15:31:01.367095Z"}},"outputs":[{"name":"stdout","text":"Splitting data into train/val/test sets...\n  Garbage: 4322 train, 927 val, 927 test\n  Potholes: 6852 train, 1469 val, 1469 test\n\n✓ Data split completed!\nFound 11174 images belonging to 2 classes.\nFound 2396 images belonging to 2 classes.\nFound 2396 images belonging to 2 classes.\n\n✓ Data generators created!\n  Training images: 11174\n  Validation images: 2396\n  Test images: 2396\n  Class indices: {'Garbage': 0, 'Potholes': 1}\n  Number of classes: 2\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"model = keras.Sequential([\n    # First convolutional block\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n    \n    # Second convolutional block\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n    \n    # Third convolutional block\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n    \n    # Fourth convolutional block\n    layers.Conv2D(256, (3, 3), activation='relu'),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n    \n    # Flatten and dense layers\n    layers.Flatten(),\n    layers.Dense(512, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(256, activation='relu'),\n    layers.Dropout(0.3),\n    layers.Dense(2, activation='softmax')\n])\n\nprint(\"✓ Model architecture created\")\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T15:33:13.929669Z","iopub.execute_input":"2026-02-07T15:33:13.930365Z","iopub.status.idle":"2026-02-07T15:33:14.036072Z","shell.execute_reply.started":"2026-02-07T15:33:13.930334Z","shell.execute_reply":"2026-02-07T15:33:14.035534Z"}},"outputs":[{"name":"stdout","text":"✓ Model architecture created\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36864\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m18,874,880\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m514\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36864</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">18,874,880</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,397,058\u001b[0m (73.99 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,397,058</span> (73.99 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,396,098\u001b[0m (73.99 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,396,098</span> (73.99 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n</pre>\n"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"model.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy', 'recall', 'precision']\n)\n\nprint(\"\\n✓ Model compiled successfully!\")\nprint(\"  Optimizer: Adam (lr=0.001)\")\nprint(\"  Loss: Categorical Crossentropy (for 2 classes)\")\nprint(\"  Metrics: Accuracy, Recall, Precision\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T15:33:22.808062Z","iopub.execute_input":"2026-02-07T15:33:22.808627Z","iopub.status.idle":"2026-02-07T15:33:22.817590Z","shell.execute_reply.started":"2026-02-07T15:33:22.808598Z","shell.execute_reply":"2026-02-07T15:33:22.816859Z"}},"outputs":[{"name":"stdout","text":"\n✓ Model compiled successfully!\n  Optimizer: Adam (lr=0.001)\n  Loss: Categorical Crossentropy (for 2 classes)\n  Metrics: Accuracy, Recall, Precision\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"callbacks = [\n    keras.callbacks.EarlyStopping(\n        monitor='val_loss',\n        patience=5,\n        restore_best_weights=True,\n        verbose=1\n    ),\n    keras.callbacks.ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.5,\n        patience=3,\n        min_lr=1e-7,\n        verbose=1\n    )\n]\n\nprint(\"✓ Callbacks configured:\")\nprint(\"  - Early Stopping (patience=5)\")\nprint(\"  - Learning Rate Reduction (patience=3)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T15:33:25.844631Z","iopub.execute_input":"2026-02-07T15:33:25.845152Z","iopub.status.idle":"2026-02-07T15:33:25.849839Z","shell.execute_reply.started":"2026-02-07T15:33:25.845123Z","shell.execute_reply":"2026-02-07T15:33:25.849148Z"}},"outputs":[{"name":"stdout","text":"✓ Callbacks configured:\n  - Early Stopping (patience=5)\n  - Learning Rate Reduction (patience=3)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*50)\nprint(\"STARTING TRAINING\")\nprint(\"=\"*50 + \"\\n\")\n\nhistory = model.fit(\n    train_generator,\n    epochs=EPOCHS,\n    validation_data=val_generator,\n    callbacks=callbacks,\n    verbose=1\n)\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"TRAINING COMPLETED!\")\nprint(\"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T15:33:29.234082Z","iopub.execute_input":"2026-02-07T15:33:29.234370Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nSTARTING TRAINING\n==================================================\n\nEpoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1770478415.196062     144 service.cc:152] XLA service 0x7fd29c008bc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1770478415.196128     144 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1770478415.196135     144 service.cc:160]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1770478415.971532     144 cuda_dnn.cc:529] Loaded cuDNN version 91002\n2026-02-07 15:33:39.251027: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n2026-02-07 15:33:39.399820: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  2/350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 90ms/step - accuracy: 0.5078 - loss: 3.6205 - precision: 0.5078 - recall: 0.5078   ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1770478424.421566     144 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m148/350\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:16\u001b[0m 678ms/step - accuracy: 0.7461 - loss: 6.3284 - precision: 0.7461 - recall: 0.7461","output_type":"stream"},{"name":"stderr","text":"2026-02-07 15:35:25.921832: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n2026-02-07 15:35:26.065321: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 781ms/step - accuracy: 0.7835 - loss: 4.6993 - precision: 0.7835 - recall: 0.7835 - val_accuracy: 0.6260 - val_loss: 2.5808 - val_precision: 0.6260 - val_recall: 0.6260 - learning_rate: 0.0010\nEpoch 2/20\n\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 738ms/step - accuracy: 0.8974 - loss: 0.3816 - precision: 0.8974 - recall: 0.8974 - val_accuracy: 0.9186 - val_loss: 0.2429 - val_precision: 0.9186 - val_recall: 0.9186 - learning_rate: 0.0010\nEpoch 3/20\n\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 766ms/step - accuracy: 0.9206 - loss: 0.2171 - precision: 0.9206 - recall: 0.9206 - val_accuracy: 0.9541 - val_loss: 0.1598 - val_precision: 0.9541 - val_recall: 0.9541 - learning_rate: 0.0010\nEpoch 4/20\n\u001b[1m112/350\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:49\u001b[0m 711ms/step - accuracy: 0.9252 - loss: 0.1919 - precision: 0.9252 - recall: 0.9252","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"Pothole Images: 9790\nGarbage Images: 1463\nTotal: 11253\nThreshold Accuracy: (9790/11253) * 100 = 86.99%\nTest Data Accuracy: ~90%\nMight overfit because model needs to be almost accurate for passing the threshold accuracy.","metadata":{}},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# Accuracy plot\nax1.plot(history.history['accuracy'], label='Train Accuracy', marker='o')\nax1.plot(history.history['val_accuracy'], label='Val Accuracy', marker='s')\nax1.set_title('Model Accuracy', fontsize=14, fontweight='bold')\nax1.set_xlabel('Epoch')\nax1.set_ylabel('Accuracy')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# Loss plot\nax2.plot(history.history['loss'], label='Train Loss', marker='o')\nax2.plot(history.history['val_loss'], label='Val Loss', marker='s')\nax2.set_title('Model Loss', fontsize=14, fontweight='bold')\nax2.set_xlabel('Epoch')\nax2.set_ylabel('Loss')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Print final metrics\nfinal_train_acc = history.history['accuracy'][-1]\nfinal_val_acc = history.history['val_accuracy'][-1]\nfinal_train_loss = history.history['loss'][-1]\nfinal_val_loss = history.history['val_loss'][-1]\n\nprint(f\"\\nFinal Training Accuracy: {final_train_acc*100:.2f}%\")\nprint(f\"Final Validation Accuracy: {final_val_acc*100:.2f}%\")\nprint(f\"Final Training Loss: {final_train_loss:.4f}\")\nprint(f\"Final Validation Loss: {final_val_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T16:02:31.602746Z","iopub.execute_input":"2026-01-13T16:02:31.603459Z","iopub.status.idle":"2026-01-13T16:02:31.958996Z","shell.execute_reply.started":"2026-01-13T16:02:31.603430Z","shell.execute_reply":"2026-01-13T16:02:31.958264Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*50)\nprint(\"EVALUATING MODEL ON VALIDATION SET\")\nprint(\"=\"*50 + \"\\n\")\n\nval_results = model.evaluate(val_generator, verbose=1)\n\nprint()\nfor name, value in zip(model.metrics_names, val_results):\n    if \"accuracy\" in name:\n        print(f\"✓ Validation {name.capitalize()}: {value*100:.2f}%\")\n    else:\n        print(f\"✓ Validation {name.capitalize()}: {value:.4f}\")\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"EVALUATING MODEL ON TEST SET\")\nprint(\"=\"*50 + \"\\n\")\n\ntest_results = model.evaluate(test_generator, verbose=1)\n\nprint()\nfor name, value in zip(model.metrics_names, test_results):\n    if \"accuracy\" in name:\n        print(f\"✓ Test {name.capitalize()}: {value*100:.2f}%\")\n    else:\n        print(f\"✓ Test {name.capitalize()}: {value:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T16:02:43.133600Z","iopub.execute_input":"2026-01-13T16:02:43.134358Z","iopub.status.idle":"2026-01-13T16:03:43.178836Z","shell.execute_reply.started":"2026-01-13T16:02:43.134318Z","shell.execute_reply":"2026-01-13T16:03:43.178088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*50)\nprint(\"GENERATING PREDICTIONS ON TEST SET\")\nprint(\"=\"*50 + \"\\n\")\n\n# Generate predictions on test set\ntest_generator.reset()\npredictions = model.predict(test_generator, verbose=1)\ny_pred = np.argmax(predictions, axis=1)  # Get class with highest probability\ny_true = test_generator.classes\n\n# Get class names\nclass_names = list(train_generator.class_indices.keys())\n\n# Classification report\nprint(\"\\n\" + \"=\"*50)\nprint(\"CLASSIFICATION REPORT (TEST SET)\")\nprint(\"=\"*50)\nprint(classification_report(y_true, y_pred, target_names=class_names))\n\n# Confusion matrix\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=class_names, yticklabels=class_names,\n            cbar_kws={'label': 'Count'})\nplt.title('Confusion Matrix (Test Set)', fontsize=16, fontweight='bold')\nplt.ylabel('True Label', fontsize=12)\nplt.xlabel('Predicted Label', fontsize=12)\nplt.tight_layout()\nplt.show()\n\n# Per-class accuracy\nprint(\"\\nPer-Class Accuracy:\")\nfor i, class_name in enumerate(class_names):\n    class_mask = y_true == i\n    class_acc = (y_pred[class_mask] == y_true[class_mask]).sum() / class_mask.sum()\n    print(f\"  {class_name}: {class_acc*100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T16:03:49.784608Z","iopub.execute_input":"2026-01-13T16:03:49.784910Z","iopub.status.idle":"2026-01-13T16:04:19.072111Z","shell.execute_reply.started":"2026-01-13T16:03:49.784881Z","shell.execute_reply":"2026-01-13T16:04:19.071535Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SAVE_DIR = \"/kaggle/working\"\nos.makedirs(SAVE_DIR, exist_ok=True)\n\nmodel.save(f\"{SAVE_DIR}/pothole_garbage_classifier_final.h5\")\nmodel.save(f\"{SAVE_DIR}/pothole_garbage_classifier_final.keras\")\n\nclass_info = {\n    'class_names': class_names,\n    'class_indices': train_generator.class_indices,\n    'num_classes': len(class_names),\n    'img_size': IMG_SIZE\n}\n\nwith open(f\"{SAVE_DIR}/class_info.json\", \"w\") as f:\n    json.dump(class_info, f, indent=4)\n\nprint(\"✓ Model and metadata saved to /kaggle/working\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T16:04:41.259550Z","iopub.execute_input":"2026-01-13T16:04:41.260209Z","iopub.status.idle":"2026-01-13T16:04:42.765460Z","shell.execute_reply.started":"2026-01-13T16:04:41.260180Z","shell.execute_reply":"2026-01-13T16:04:42.764711Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_for_single_image(img_path, show_plot=True):\n    \"\"\"\n    Predict class of a single image\n    \n    Args:\n        img_path: Path to the image file\n        show_plot: Whether to display the image with prediction\n    \n    Returns:\n        tuple: (class_name, confidence, all_probabilities)\n    \"\"\"\n    # Load and preprocess image\n    img = keras.preprocessing.image.load_img(img_path, target_size=IMG_SIZE)\n    img_array = keras.preprocessing.image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0) / 255.0\n    \n    # Make prediction\n    predictions = model.predict(img_array, verbose=0)[0]\n    class_idx = np.argmax(predictions)\n    class_name = class_names[class_idx]\n    confidence = predictions[class_idx]\n    \n    # Display result\n    if show_plot:\n        plt.figure(figsize=(10, 6))\n        \n        # Image subplot\n        plt.subplot(1, 2, 1)\n        plt.imshow(img)\n        plt.title(f'Prediction: {class_name.upper()}\\nConfidence: {confidence*100:.2f}%', \n                  fontsize=12, fontweight='bold')\n        plt.axis('off')\n        \n        # Probability bar chart\n        plt.subplot(1, 2, 2)\n        colors = ['green' if i == class_idx else 'gray' for i in range(len(class_names))]\n        plt.barh(class_names, predictions * 100, color=colors)\n        plt.xlabel('Confidence (%)', fontsize=10)\n        plt.title('Class Probabilities', fontsize=12, fontweight='bold')\n        plt.xlim(0, 100)\n        \n        plt.tight_layout()\n        plt.show()\n    \n    return class_name, confidence, predictions\n\nprint(\"✓ Prediction function defined\")\nprint(\"\\nUsage example:\")\nprint(\"  predict_image('/path/to/image.jpg')\")\nprint(\"\\nReturns: (class_name, confidence, all_probabilities)\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T16:05:00.038820Z","iopub.execute_input":"2026-01-13T16:05:00.039375Z","iopub.status.idle":"2026-01-13T16:05:00.046937Z","shell.execute_reply.started":"2026-01-13T16:05:00.039345Z","shell.execute_reply":"2026-01-13T16:05:00.046267Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model to get the test accuracy\nresults = model.evaluate(test_generator, verbose=1)\n\n# results[0] is usually loss, results[1] is usually accuracy\ntest_acc = results[1] \n\n# Now your print statement will work!\nprint(f\"Test Accuracy: {test_acc*100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T16:10:41.939980Z","iopub.execute_input":"2026-01-13T16:10:41.940497Z","iopub.status.idle":"2026-01-13T16:11:11.718645Z","shell.execute_reply.started":"2026-01-13T16:10:41.940464Z","shell.execute_reply":"2026-01-13T16:11:11.717353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*50)\nprint(\"SAMPLE PREDICTIONS ON TEST DATA\")\nprint(\"=\"*50 + \"\\n\")\n\ntest_generator.reset()\ntest_generator = val_test_datagen.flow_from_directory(\n    TEST_DIR,\n    target_size=(224, 224),\n    batch_size=32,\n    shuffle=True) # This ensures a mix of Potholes and Garbage\nx_batch, y_batch = next(test_generator)\npredictions_batch = model.predict(x_batch, verbose=0)\n\nplt.figure(figsize=(15, 10))\nfor i in range(min(12, len(x_batch))):\n    plt.subplot(3, 4, i + 1)\n    plt.imshow(x_batch[i])\n    \n    true_class_idx = np.argmax(y_batch[i])\n    pred_class_idx = np.argmax(predictions_batch[i])\n    \n    true_class = class_names[true_class_idx]\n    pred_class = class_names[pred_class_idx]\n    confidence = predictions_batch[i][pred_class_idx]\n    \n    # Color code: green if correct, red if wrong\n    color = 'green' if true_class == pred_class else 'red'\n    \n    plt.title(f'True: {true_class}\\nPred: {pred_class} ({confidence*100:.1f}%)', \n              fontsize=9, color=color, fontweight='bold')\n    plt.axis('off')\n\nplt.suptitle('Sample Predictions on Test Set (Green=Correct, Red=Incorrect)', \n             fontsize=16, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"ALL BLOCKS COMPLETED SUCCESSFULLY!\")\nprint(\"=\"*50)\nprint(f\"\\nFinal Results Summary:\")\nprint(f\"  Classes: {class_names}\")\nprint(f\"  Test Accuracy: {test_acc*100:.2f}%\")\nprint(f\"  Model saved as: pothole_garbage_classifier.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T16:17:08.094941Z","iopub.execute_input":"2026-01-13T16:17:08.095471Z","iopub.status.idle":"2026-01-13T16:17:09.392931Z","shell.execute_reply.started":"2026-01-13T16:17:08.095441Z","shell.execute_reply":"2026-01-13T16:17:09.392083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"For i1 we got {predict_for_single_image( '/kaggle/input/helpppp/helppp/i1.png')}\")\nprint(f\"For i11 we got {predict_for_single_image( '/kaggle/input/helpppp/helppp/i11.jpeg')}\")\nprint(f\"For i2 we got {predict_for_single_image( '/kaggle/input/helpppp/helppp/i2.png')}\")\nprint(f\"For i3 we got {predict_for_single_image( '/kaggle/input/helpppp/helppp/i3.png')}\")\nprint(f\"For n1 we got {predict_for_single_image( '/kaggle/input/helpppp/helppp/n1.jpg')}\")\nprint(f\"For n2 we got {predict_for_single_image( '/kaggle/input/helpppp/helppp/n2.jpg')}\")\nprint(f\"For n3 we got {predict_for_single_image( '/kaggle/input/helpppp/helppp/n3.png')}\")\nprint(f\"For n4 we got {predict_for_single_image( '/kaggle/input/helpppp/helppp/n4.jpeg')}\")\nprint(f\"For boomer we got {predict_for_single_image( '/kaggle/input/helpppp/helppp/n4.jpeg')}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T16:17:51.570062Z","iopub.execute_input":"2026-01-13T16:17:51.570501Z","iopub.status.idle":"2026-01-13T16:17:55.577925Z","shell.execute_reply.started":"2026-01-13T16:17:51.570474Z","shell.execute_reply":"2026-01-13T16:17:55.577219Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Create the directory if it doesn't exist\nmodel_dir = \"/kaggle/working/models\"\nif not os.path.exists(model_dir):\n    os.makedirs(model_dir)\n\n# 2. Save trained model into that folder\nmodel.save(f\"{model_dir}/pothole_garbage_classifier.h5\")\n\n# 3. Zip the folder\nshutil.make_archive(\"/kaggle/working/models_download\", 'zip', model_dir)\n\nprint(\"✅ Model saved and zipped successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T16:20:00.895449Z","iopub.execute_input":"2026-01-13T16:20:00.896091Z","iopub.status.idle":"2026-01-13T16:20:12.371395Z","shell.execute_reply.started":"2026-01-13T16:20:00.896064Z","shell.execute_reply":"2026-01-13T16:20:12.370566Z"}},"outputs":[],"execution_count":null}]}